# E2E test values with MaaS (Model-as-a-Service) integration
# This extends values-e2e.yaml with MaaS inference capability
# Enables full e2e testing including chat completions and RAG queries

replicaCount: 1

image:
  repository: quay.io/ecosystem-appeng/llamastack-dist-ui
  pullPolicy: IfNotPresent
  tag: "0.2.14"

service:
  type: ClusterIP
  port: 8501

serviceAccount:
  create: false

livenessProbe:
  httpGet:
    path: /
    port: http
  initialDelaySeconds: 30
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 6

readinessProbe:
  httpGet:
    path: /
    port: http
  initialDelaySeconds: 20
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 3

env:
  - name: LLAMA_STACK_ENDPOINT
    value: 'http://llamastack:8321'

volumes:
  - emptyDir: {}
    name: dot-streamlit

volumeMounts:
  - mountPath: /.streamlit
    name: dot-streamlit

# Configure models to use Red Hat MaaS
# All MaaS configuration (url, id, enabled, apiToken) will be injected via helm --set in GitHub Actions
# This allows flexible configuration from workflow environment variables
global:
  models: {}
    # Example structure (populated by workflow):
    # llama-3-2-3b:
    #   url: "https://maas-endpoint/v1"
    #   id: "llama-3-2-3b"
    #   enabled: true
    #   apiToken: "secret-key"

# PostgreSQL + PGVector configuration
pgvector:
  enabled: true
  secret:
    user: postgres
    password: test_password
    dbname: rag_test_db
    host: pgvector
    port: "5432"
  resources:
    requests:
      memory: "512Mi"
      cpu: "500m"
    limits:
      memory: "1Gi"
      cpu: "1"

# MinIO configuration
minio:
  enabled: true
  secret:
    user: minio_test_user
    password: minio_test_password
    host: minio
    port: "9000"
  resources:
    requests:
      memory: "256Mi"
      cpu: "250m"
    limits:
      memory: "512Mi"
      cpu: "500m"
  
  # Upload sample files - Disabled (requires OpenShift tools image)
  sampleFileUpload:
    enabled: false
    bucket: documents
    urls: []

# Llama Stack configuration for MaaS
llama-stack:
  enabled: true
  secrets:
    TAVILY_SEARCH_API_KEY: ""
  
  resources:
    requests:
      memory: "512Mi"
      cpu: "500m"
    limits:
      memory: "1Gi"
      cpu: "1"
  
  # Skip waiting for models since we're using external MaaS
  # Override init containers to prevent waiting for local models
  initContainers: []
  # Don't wait for models - they're external via MaaS
  skipModelWait: true

# Disable components that require OpenShift/KServe CRDs
llm-service:
  enabled: false

configure-pipeline:
  enabled: false
  persistence:
    enabled: false
  pvc:
    create: false

# MCP servers
mcp-servers:
  enabled: false

# Data ingestion pipeline - Disabled for Kind (requires OpenShift internal registry)
# The ingestion pipeline uses OpenShift-specific images that aren't available in Kind
# For full RAG testing, this would need to be enabled in an OpenShift environment
ingestion-pipeline:
  enabled: false
  replicaCount: 0
  defaultPipeline:
    enabled: false

