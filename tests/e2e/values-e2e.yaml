# E2E test values for kind cluster deployment
# Optimized for minimal resources and fast startup

replicaCount: 1

image:
  repository: quay.io/ecosystem-appeng/llamastack-dist-ui
  pullPolicy: IfNotPresent
  tag: "0.2.14"

service:
  type: ClusterIP
  port: 8501

serviceAccount:
  create: false

livenessProbe:
  httpGet:
    path: /
    port: http
  initialDelaySeconds: 30
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 6

readinessProbe:
  httpGet:
    path: /
    port: http
  initialDelaySeconds: 20
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 3

env:
  - name: LLAMA_STACK_ENDPOINT
    value: 'http://llamastack:8321'

volumes:
  - emptyDir: {}
    name: dot-streamlit

volumeMounts:
  - mountPath: /.streamlit
    name: dot-streamlit

# Simplified model configuration for E2E tests
# Using CPU and minimal resources
global:
  models:
    llama-3-2-3b-instruct:
      id: meta-llama/Llama-3.2-3B-Instruct
      enabled: true
      device: "cpu"
      resources:
        requests:
          memory: "4Gi"
          cpu: "2"
        limits:
          memory: "8Gi"
          cpu: "4"
      args:
      - --enable-auto-tool-choice
      - --chat-template
      - /vllm-workspace/examples/tool_chat_template_llama3.2_json.jinja
      - --tool-call-parser
      - llama3_json
      - --max-model-len
      - "4096"
      - --max-num-seqs
      - "16"
  mcp-servers: {}

# PostgreSQL + PGVector configuration
pgvector:
  secret:
    user: postgres
    password: test_password
    dbname: rag_test_db
    host: pgvector
    port: 5432
  resources:
    requests:
      memory: "512Mi"
      cpu: "500m"
    limits:
      memory: "1Gi"
      cpu: "1"

# MinIO configuration
minio:
  secret:
    user: minio_test_user
    password: minio_test_password
    host: minio
    port: 9000
  resources:
    requests:
      memory: "256Mi"
      cpu: "250m"
    limits:
      memory: "512Mi"
      cpu: "500m"
  
  # Upload sample files for testing
  sampleFileUpload:
    enabled: true
    bucket: documents
    urls: 
    - https://raw.githubusercontent.com/rh-ai-quickstart/RAG/refs/heads/main/notebooks/Zippity_Zoo_Grand_Invention.pdf

# Llama Stack configuration
llama-stack:
  secrets:
    TAVILY_SEARCH_API_KEY: ""
  resources:
    requests:
      memory: "512Mi"
      cpu: "500m"
    limits:
      memory: "1Gi"
      cpu: "1"

# Data ingestion pipeline - disabled for basic e2e tests
ingestion-pipeline:
  defaultPipeline:
    enabled: false
