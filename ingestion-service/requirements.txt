llama-stack-client==0.2.22
pyyaml>=6.0
boto3>=1.34.0
requests>=2.31.0
docling>=2.0.0
docling-core>=2.0.0
GitPython>=3.1.40
# Explicitly avoid CUDA dependencies for CPU-only deployment
--extra-index-url https://download.pytorch.org/whl/cpu
torch>=2.0.0
torchvision>=0.15.0
# Use headless OpenCV for server environments (no GUI/OpenGL dependencies)
opencv-python-headless>=4.5.1.48
