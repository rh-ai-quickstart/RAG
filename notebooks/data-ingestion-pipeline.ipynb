{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45265ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install boto3\n",
    "!pip install kfp\n",
    "!pip install llama-stack-client==0.2.17\n",
    "!pip install fire\n",
    "!pip install requests\n",
    "!pip install docling\n",
    "!pip install docling-core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fce794-07aa-406f-ac77-343747fe6de5",
   "metadata": {},
   "source": [
    "## Ingestion Pipeline\n",
    "This pipeline executes the following:\n",
    "- fetches pdf documents from Minio\n",
    "- chunks and embeds them with docling\n",
    "- stores the data in Postgres Vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dacf488-7fe9-4210-a1e9-e9c5f154c38e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"https://ds-pipeline-dspa.llama-stack-rag-2.svc.cluster.local:8888/#/pipelines/details/94964c23-6176-4c5a-bcd6-fef1209fbb85\" target=\"_blank\" >Pipeline details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"https://ds-pipeline-dspa.llama-stack-rag-2.svc.cluster.local:8888/#/experiments/details/4aa20837-a570-4965-894b-a143a7420fce\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"https://ds-pipeline-dspa.llama-stack-rag-2.svc.cluster.local:8888/#/runs/details/751e0d06-cd93-4e71-99e0-1ea3d04cda09\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline submitted! Run ID: 751e0d06-cd93-4e71-99e0-1ea3d04cda09\n"
     ]
    }
   ],
   "source": [
    "from kfp.dsl import component, pipeline\n",
    "from kfp.v2 import compiler\n",
    "from kfp import Client\n",
    "from kfp.v2 import compiler\n",
    "from kfp.dsl import pipeline\n",
    "\n",
    "@component(\n",
    "    base_image=\"python:3.10\",\n",
    "    packages_to_install=[\n",
    "        \"boto3\",\n",
    "        \"llama-stack-client==0.2.9\",\n",
    "        \"fire\",\n",
    "        \"requests\",\n",
    "        \"docling\",\n",
    "        \"docling-core\"\n",
    "    ])\n",
    "def fetch_from_minio_docling_process_store(bucket_name: str, minio_endpoint: str, minio_access_key: str, minio_secret_key: str, llamastack_base_url: str):\n",
    "    import os\n",
    "    import boto3\n",
    "    import tempfile\n",
    "    from llama_stack_client import LlamaStackClient\n",
    "    from llama_stack_client.types import Document as LlamaStackDocument\n",
    "\n",
    "    # Import docling libraries\n",
    "    from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "    from docling.datamodel.base_models import InputFormat\n",
    "    from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "    from docling_core.transforms.chunker.hybrid_chunker import HybridChunker\n",
    "    from docling_core.types.doc.labels import DocItemLabel\n",
    "\n",
    "    # Step 1: Download files from MinIO\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    download_dir = os.path.join(temp_dir, \"source_repo\")\n",
    "    os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "    # Connect to MinIO\n",
    "    print(f\"Connecting to MinIO at {minio_endpoint}\")\n",
    "    s3 = boto3.client(\n",
    "        \"s3\",\n",
    "        endpoint_url=minio_endpoint,\n",
    "        aws_access_key_id=minio_access_key,\n",
    "        aws_secret_access_key=minio_secret_key,\n",
    "        verify=False\n",
    "    )\n",
    "\n",
    "    # List and download objects\n",
    "    paginator = s3.get_paginator(\"list_objects_v2\")\n",
    "    pages = paginator.paginate(Bucket=bucket_name)\n",
    "\n",
    "    print(f\"Downloading files from bucket: {bucket_name}\")\n",
    "    downloaded_files = []\n",
    "    for page in pages:\n",
    "        for obj in page.get(\"Contents\", []):\n",
    "            key = obj[\"Key\"]\n",
    "            file_path = os.path.join(download_dir, os.path.basename(key))\n",
    "            print(f\"Downloading: {key} -> {file_path}\")\n",
    "            s3.download_file(bucket_name, key, file_path)\n",
    "            downloaded_files.append(file_path)\n",
    "\n",
    "    print(f\"Downloaded {len(downloaded_files)} files to {download_dir}\")\n",
    "\n",
    "    # Step 2: Process the PDFs with docling\n",
    "    # Setup docling components\n",
    "    pipeline_options = PdfPipelineOptions()\n",
    "    pipeline_options.generate_picture_images = True\n",
    "    converter = DocumentConverter(\n",
    "                format_options={\n",
    "                    InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
    "                }\n",
    "    )\n",
    "    chunker = HybridChunker()\n",
    "    llama_documents = []\n",
    "    i = 0\n",
    "\n",
    "    # Process each file with docling (chunking)\n",
    "    for file_path in downloaded_files:\n",
    "        if not file_path.endswith(\".pdf\"):\n",
    "            print(f\"Skipping non-PDF file: {file_path}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing {file_path} with docling...\")\n",
    "        try:\n",
    "            docling_doc = converter.convert(source=file_path).document\n",
    "            chunks = chunker.chunk(docling_doc)\n",
    "            chunk_count = 0\n",
    "\n",
    "            for chunk in chunks:\n",
    "                if any(\n",
    "                    c.label in [DocItemLabel.TEXT, DocItemLabel.PARAGRAPH]\n",
    "                    for c in chunk.meta.doc_items\n",
    "                ):\n",
    "                    i += 1\n",
    "                    chunk_count += 1\n",
    "                    llama_documents.append(\n",
    "                        LlamaStackDocument(\n",
    "                            document_id=f\"doc-{i}\",\n",
    "                            content=chunk.text,\n",
    "                            mime_type=\"text/plain\",\n",
    "                            metadata={\"source\": os.path.basename(file_path)},\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "            print(f\"Created {chunk_count} chunks from {file_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            error_message = str(e)\n",
    "            print(f\"Error processing {file_path}: {error_message}\")\n",
    "\n",
    "    total_chunks = len(llama_documents)\n",
    "    print(f\"Total valid chunks prepared: {total_chunks}\")\n",
    "\n",
    "    # Step 3: Register vector database and store chunks with embeddings\n",
    "    client = LlamaStackClient(base_url=llamastack_base_url)\n",
    "    print(\"Registering db\")\n",
    "    try:\n",
    "        client.vector_dbs.register(\n",
    "            vector_db_id=\"test\",\n",
    "            embedding_model=\"all-MiniLM-L6-v2\",\n",
    "            embedding_dimension=384,\n",
    "            provider_id=\"pgvector\",\n",
    "        )\n",
    "        print(\"Vector DB registered successfully\")\n",
    "    except Exception as e:\n",
    "        error_message = str(e)\n",
    "        print(f\"Failed to register vector DB: {error_message}\")\n",
    "        print(\"Continuing with insertion...\")\n",
    "\n",
    "    try:\n",
    "        print(f\"Inserting {total_chunks} chunks into vector database\")\n",
    "        client.tool_runtime.rag_tool.insert(\n",
    "            documents=llama_documents,\n",
    "            vector_db_id=\"test\",\n",
    "            chunk_size_in_tokens=512,\n",
    "        )\n",
    "        print(\"Documents successfully inserted into the vector DB\")\n",
    "    except Exception as e:\n",
    "        print(\"Embedding insert failed:\", e)\n",
    "\n",
    "\n",
    "@pipeline(name=\"fetch-docling-process-store-pipeline\")\n",
    "def full_pipeline():\n",
    "    import os\n",
    "\n",
    "    fetch_from_minio_docling_process_store(\n",
    "        bucket_name=\"llama\",\n",
    "        minio_endpoint=os.environ[\"MINIO_ENDPOINT\"],\n",
    "        minio_access_key=os.environ[\"MINIO_ACCESS_KEY\"],\n",
    "        minio_secret_key=os.environ[\"MINIO_SECRET_KEY\"],\n",
    "        llamastack_base_url=os.environ[\"LLAMASTACK_BASE_URL\"]\n",
    "    )\n",
    "\n",
    "# 1. Compile pipeline to a file\n",
    "pipeline_yaml = \"fetch_docling_process_pipeline.yaml\"\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=full_pipeline,\n",
    "    package_path=pipeline_yaml\n",
    ")\n",
    "\n",
    "# 2. Connect to KFP\n",
    "client = Client(\n",
    "    host=\"https://ds-pipeline-dspa:8888\",\n",
    "    verify_ssl=False\n",
    ")\n",
    "\n",
    "# 3. Upload pipeline\n",
    "uploaded_pipeline = client.upload_pipeline(\n",
    "    pipeline_package_path=pipeline_yaml,\n",
    "    pipeline_name=\"fetch-docling-process-store-pipeline\"\n",
    ")\n",
    "\n",
    "# 4. Run the pipeline\n",
    "run = client.create_run_from_pipeline_package(\n",
    "    pipeline_file=pipeline_yaml,\n",
    "    arguments={},\n",
    "    run_name=\"fetch-docling-process-store-run\"\n",
    ")\n",
    "\n",
    "print(f\"Pipeline submitted! Run ID: {run.run_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5bd908-4d70-47ac-b1c4-606aaf806f46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
