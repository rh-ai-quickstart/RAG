# RAG Stack Configuration Values
# Copy this file to rag-values.yaml and customize the values
# The rag-values.yaml file is ignored by git to prevent accidental commits

# API Keys and Tokens
# Set your API keys and tokens here
# These will be used by the Helm chart during installation

# Hugging Face Token (required for model downloads)
# Get your token from: https://huggingface.co/settings/tokens
# Set this in the llm-service.secret.hf_token field below

# TAVILY Search API Key is configured in the llama-stack.secrets section below

# LLM Service Configuration
llm-service:
  secret:
    hf_token: ""
    enabled: true

# Global model configuration
global:
  models:
    # Pre-configured LLM models
    # To deploy the model, set the enabled flag to true 
    # For detailed model configuration visit the url of the `llm-service` helm chart at 
    # https://github.com/rh-ai-quickstart/ai-architecture-charts/blob/main/llm-service/helm/values.yaml 

    llama-3-2-1b-instruct:
      id: meta-llama/Llama-3.2-1B-Instruct
      enabled: false

    llama-3-1-8b-instruct:
      id: meta-llama/Llama-3.1-8B-Instruct
      enabled: false

    llama-3-2-1b-instruct-quantized:
      id: RedHatAI/Llama-3.2-1B-Instruct-quantized.w8a8
      enabled: false

    llama-3-2-3b-instruct:
      id: meta-llama/Llama-3.2-3B-Instruct
      enabled: false

    llama-3-3-70b-instruct:
      id: meta-llama/Llama-3.3-70B-Instruct
      enabled: false

    llama-3-3-70b-instruct-quantization-fp8:
      id: meta-llama/Llama-3.3-70B-Instruct
      enabled: false

    llama-guard-3-1b:
      id: meta-llama/Llama-Guard-3-1B
      enabled: false

    llama-guard-3-8b:
      id: meta-llama/Llama-Guard-3-8B
      enabled: false

    qwen-2-5-vl-3b-instruct:
      id: Qwen/Qwen2.5-VL-3B-Instruct
      enabled: false
    
    # To configure LlamaStack with remote llm, replace the id,
    # url and apiToken value and set enabled to true

    # remote-llm:
    #   id: custom-model-id
    #   url: https://custom-server-url/v1
    #   apiToken: fake-token
    #   enabled: false

    # To deploy custom models on RHOAI use the following code snippet

    # Example safety model configuration
    # custom-llm:
    #   id: meta-llama/Llama-3.2-1B-Instruct
    #   enabled: true
    #   device: "gpu"  # Options: "cpu", "gpu", "hpu"
    #   resources:
    #     limits:
    #       nvidia.com/gpu: "1"
    #   tolerations:
    #   - key: "nvidia.com/gpu"
    #     operator: Exists
    #     effect: NoSchedule
    #   args:
    #   - --max-model-len
    #   - "14336"
    
    # Example safety model configuration
    # custom-safety-guard:
    #   id: meta-llama/Llama-Guard-3-8B
    #   enabled: true
    #   registerShield: true
    #   device: "gpu"
    #   resources:
    #     limits:
    #       nvidia.com/gpu: "1"
    #   tolerations:
    #   - key: "nvidia.com/gpu"
    #     operator: Exists
    #     effect: NoSchedule

  # MCP servers configuration
  mcp-servers: {}

# Database Configuration (pgvector)
pgvector:
  secret:
    user: "postgres"
    password: "rag_password"
    dbname: "rag_blueprint"
    host: "pgvector"
    port: "5432"

# MinIO Configuration
minio:
  secret:
    user: "minio_rag_user"
    password: "minio_rag_password"
    host: "minio"
    port: "9000"
  
  # Upload sample files to the minio bucket 
  sampleFileUpload:
    enabled: true
    bucket: "documents"
    urls: 
    - "https://raw.githubusercontent.com/rh-ai-quickstart/RAG/refs/heads/main/notebooks/Zippity_Zoo_Grand_Invention.pdf"
    - "https://raw.githubusercontent.com/rh-ai-quickstart/RAG/refs/heads/main/notebooks/Zippity_Zoo_and_the_Town_of_Tumble_Town.pdf"
    - "https://raw.githubusercontent.com/rh-ai-quickstart/RAG/refs/heads/main/notebooks/Zippity_Zoo_and_the_Town_of_Whispering_Willows.pdf"

# Llama Stack Configuration
llama-stack:
  secrets:
    # TAVILY Search API Key for web search functionality
    TAVILY_SEARCH_API_KEY: "Paste-your-key-here"
    
    # Add other API keys as needed
    # OPENAI_API_KEY: "your_openai_key_here"
    # ANTHROPIC_API_KEY: "your_anthropic_key_here"

# Ingestion Pipeline Configuration
ingestion-pipeline:
  pipelines:
    # GitHub-based pipeline
    hr-pipeline:
      enabled: true
      source: GITHUB
      embedding_model: "all-MiniLM-L6-v2"
      name: "hr-vector-db"
      version: "1.0"
      vector_store_name: "hr-vector-db-v1-0"
      GITHUB:
        url: https://github.com/rh-ai-quickstart/RAG.git
        path: notebooks/hr
        token: auth_token
        branch: main

    legal-pipeline:
      enabled: true
      source: GITHUB
      embedding_model: "all-MiniLM-L6-v2"
      name: "legal-vector-db"
      version: "1.0"
      vector_store_name: "legal-vector-db-v1-0"
      GITHUB:
        url: https://github.com/rh-ai-quickstart/RAG.git
        path: notebooks/legal
        token: auth_token
        branch: main

    sales-pipeline:
      enabled: true
      source: GITHUB
      embedding_model: "all-MiniLM-L6-v2"
      name: "sales-vector-db"
      version: "1.0"
      vector_store_name: "sales-vector-db-v1-0"
      GITHUB:
        url: https://github.com/rh-ai-quickstart/RAG.git
        path: notebooks/sales
        token: auth_token
        branch: main

    procurement-pipeline:
      enabled: true
      source: GITHUB
      embedding_model: "all-MiniLM-L6-v2"
      name: "procurement-vector-db"
      version: "1.0"
      vector_store_name: "procurement-vector-db-v1-0"
      GITHUB:
        url: https://github.com/rh-ai-quickstart/RAG.git
        path: notebooks/procurement
        token: auth_token
        branch: main

    techsupport-pipeline:
      enabled: true
      source: GITHUB
      embedding_model: "all-MiniLM-L6-v2"
      name: "techsupport-vector-db"
      version: "1.0"
      vector_store_name: "techsupport-vector-db-v1-0"
      GITHUB:
        url: https://github.com/rh-ai-quickstart/RAG.git
        path: notebooks/techsupport
        token: auth_token
        branch: main

# UI Configuration
replicaCount: 1

image:
  repository: "quay.io/rh-ai-quickstart/llamastack-dist-ui"
  pullPolicy: "Always"

env:
  - name: "LLAMA_STACK_ENDPOINT"
    value: "http://llamastack:8321"
  - name: "RAG_QUESTION_SUGGESTIONS"
    value: |
      {
        "hr-vector-db-v1-0": [
          "What are the health insurance benefits offered?",
          "How many vacation days do employees get?",
          "What is the parental leave policy?",
          "What are the retirement benefits?",
          "How do I enroll in benefits?",
          "What is the employee assistance program?"
        ],
        "legal-vector-db-v1-0": [
          "What are the key contract terms?",
          "What is the liability clause?",
          "What are the termination conditions?",
          "What are the intellectual property rights?",
          "What is the dispute resolution process?",
          "What are the compliance requirements?"
        ],
        "sales-vector-db-v1-0": [
          "What is the sales process?",
          "How do I qualify leads?",
          "What are the pricing strategies?",
          "What is the commission structure?",
          "How do I handle customer objections?",
          "What are the territory assignments?"
        ],
        "procurement-vector-db-v1-0": [
          "What is the procurement process?",
          "How do I submit a purchase request?",
          "What are the approval requirements?",
          "Who are the approved vendors?",
          "What is the purchasing policy?",
          "How do I track my order?"
        ],
        "techsupport-vector-db-v1-0": [
          "How do I install CloudSync on Mac?",
          "How do I install CloudSync on Windows?",
          "How do I sync files between devices?",
          "How do I troubleshoot CloudSync sync issues?",
          "How do I install Linux on TechGear Pro Laptop?",
          "Where can I find video drivers for TechGear Pro?"
        ]
      }

